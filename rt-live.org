# -*- org-confirm-babel-evaluate: nil -*- 
#+author:      Thomas P. Harte
#+title:       Estimating COVID-19's $R_t$ in Real-Time
#+email:       tharte@cantab.net
#+property:      :tangle yes :exports code :results output
#+html_mathjax:  align:"left" path:"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"
#+html_head:     <link rel="stylesheet" type="text/css" href="github.css"/>
#+infojs_opt:    view: info toc:t

#+latex_class:   review
#+latex_header:  \usepackage{minted}
#+latex_header:  \usemintedstyle{colorful}
#+latex_header:  \usepackage[ruled]{algorithm2e}
#+latex_header:  \usepackage{enumitem}
#+options:       tex:imagemagick
#+include:       /home/tharte/dot/include/newcommands.tex src latex
#+bind:          org-latex-image-default-width 0.5\linewidth $
#+bind:          org-latex-prefer-user-labels t
#+latex_header:  \newtheorem{lemma}{Lemma}[section]
#+latex_header:  \newtheorem{defn}{Definition}[section]
#+latex_header:  \newtheorem{remark}{Remark}[section]

#+latex_header_extra: \usepackage{mdframed}
#+latex_header_extra: \BeforeBeginEnvironment{verbatim}{\begin{mdframed}}
#+latex_header_extra: \AfterEndEnvironment{verbatim}{\end{mdframed}}

#+begin_export latex
\newtcbox{\mybox}[1][]{%
    nobeforeafter, math upper, tcbox raise base,
    enhanced, colframe=blue!30!black,
    colback=lightgreen!30, boxrule=0.5pt,
    #1
}
#+end_export


Original author: Kevin Systrom - April 17.

Source: 
1. https://rt.live/
2. https://github.com/k-sys/covid-19
   
#+begin_src python :session *Python-3.x* :exports none :results silent
# notebook-specific functions
%run rt_live_functions.py
from IPython.display import clear_output

get_ipython().run_line_magic('config', "InlineBackend.figure_format = 'retina'")
#+end_src

#+BEGIN_SRC python :session *Python-3.x* :exports none :results silent :eval no
# org-specific functions
matplotlib.use('Agg')  # Agg backend for non-interactive use with Org

sys.path.insert(0, '/home/tharte/j/proj/wrex')
from wrex.tools.utils import *
#+END_SRC

Temporary reference to avoid issues with BibTeX:
\cite[Online peer-reviewed journal]{Bettencourt:08}

* Introduction
In any epidemic, $R_t$ is the measure known as the 
/effective reproduction number/. 
It's the number of people who become infected per infectious person at
time $t$. The most well-known version of this number is the basic reproduction
number: $R_0$ when $t=0$. However, $R_0$ is a single measure that does not
adapt with changes in behavior and restrictions.

As a pandemic evolves, increasing restrictions (or potential releasing of
restrictions) changes $R_t$. Knowing the current $R_t$ is essential. When
$R\gg 1$, the pandemic will spread through a large part of the population. If
$R_t<1$, the pandemic will slow quickly before it has a chance to infect many
people. The lower the $R_t$: the more manageable the situation. In general,
any $R_t<1$ means things are under control.

The value of $R_t$ helps us in two ways. 
1. It helps us understand how effective our measures have been controlling an 
   outbreak and 
2. It gives us vital information about whether we should
   increase or reduce restrictions based on our competing goals of
   economic prosperity and human safety. 
   [[https://www.nytimes.com/2020/04/06/opinion/coronavirus-end-social-distancing.html][Well-respected epidemiologists argue]]
   that tracking $R_t$ is the only way to manage through this crisis.

Yet, today, we don't yet use $R_t$ in this way. In fact,
the only real-time measure I've seen has been for 
[[https://covid19.sph.hku.hk/dashboard][Hong Kong]]. 
More importantly, it is not useful to understand $R_t$ at a national
level. Instead, to manage this crisis effectively, we need a local (state,
county and/or city) granularity of $R_t$.

What follows is a solution to this problem at the US State level. It's a
modified version of a solution created by \cite{Bettencourt:08} to estimate
real-time $R_t$ using a Bayesian approach. While this paper estimates a
static $R$ value, here we introduce a process model with Gaussian noise to
estimate a time-varying $R_t$.

If you have questions, comments, or improvments feel free to get in touch:
[[mailto:hello@systrom.com][hello@systrom.com]]. 
And if it's not entirely clear, I'm not an epidemiologist. 
At the same time, data is data, and statistics are statistics and this
is based on work by well-known epidemiologists so you can calibrate your
beliefs as you wish. In the meantime, I hope you can learn something new
as I did by reading through this example. Feel free to take this work and
apply it elsewhere â€“ internationally or to counties in the United States.

Additionally, a huge thanks to [[http://www.twitter.com/fdellaert][Frank Dellaert]] who suggested the addition
of the process and to [[http://www.twitter.com/adamlerer][Adam Lerer]] who implemented the changes. 
Not only did I learn something new, it made the model much more responsive.

** Bettencourt & Ribeiro's Approach
Every day, we learn how many more people have COVID-19. This new case count
gives us a clue about the current value of $R_t$. We also, figure that the
value of $R_t$ today is related to the value of $R_{t-1}$ (yesterday's value)
and every previous value of $R_{t-m}$ for that matter.

With these insights, the authors use 
[[https://en.wikipedia.org/wiki/Bayes%27_theorem][Bayes' rule]] 
to update their beliefs about the true value of $R_t$ based on how many new
cases have been reported each day.

This is Bayes' Theorem as we'll use it:
\begin{align*}
    \Pr(R_t\mid k) &= \frac{\Pr(k\mid R_t) \cdot \Pr(R_t)}{\Pr(k)} 
\end{align*}

This says that, having seen $k$ new cases, we believe the distribution of
$R_t$ is equal to:

- The *likelihood* of seeing $k$ new cases given $R_t$ times \dots
- The *prior* beliefs of the value of $\Pr(R_t)$ without the data \dots
- divided by the probability of seeing this many cases in general.
  
This is for a single day. To make it iterative: every day that passes, we use
yesterday's prior $\Pr(R_{t-1})$ to estimate today's prior $\Pr(R_t)$. We will
assume the distribution of $R_t$ to be a Gaussian centered around $R_{t-1}$, so 
\begin{align*}
    \Pr(R_t\mid R_{t-1}) &= \mathscr{N}(R_{t-1}, \sigma), 
\end{align*}
where $\sigma$ is a
hyperparameter (see below on how we estimate $\sigma$). So on day one:
\begin{align*}
    \Pr(R_1|k_1) &\propto \Pr(R_1)\cdot \mathscr{L}(R_1 \mid k_1)
\end{align*}
On day two:
\begin{align*}
    \Pr(R_2|k_1,k_2) 
        &\propto \Pr(R_2)\cdot \mathscr{L}(R_2|k_2) \\
        &= \sum_{R_1} {\Pr(R_1|k_1)\cdot \Pr(R_2|R_1)\cdot\mathscr{L}(R_2|k_2) }
\end{align*}
etc.

** Choosing a Likelihood Function $Pr\left(k_t\mid R_t\right)$
A likelihood function function says how likely we are to see $k$ new cases,
given a value of $R_t$.

Any time you need to model ``arrivals'' over some time
period of time, statisticians like to use the 
[[Poisson Distribution][https://en.wikipedia.org/wiki/Poisson_distribution]].
Given an average arrival rate of $\lambda$ new cases per day, the probability of
seeing $k$ new cases is distributed according to the Poisson distribution:
\begin{align*}
    \Pr(k\mid\lambda) &= \frac{\lambda^k e^{-\lambda}}{k!}
\end{align*}

#+begin_src python :session *Python-3.x* :exports both :results output
# Column vector of k
k = np.arange(0, 70)[:, None]

# Different values of Lambda
lambdas = [10, 20, 30, 40]

# Evaluated the Probability Mass Function (remember: poisson is discrete)
y = sps.poisson.pmf(k, lambdas)

# Show the resulting shape
print(y.shape)
#+end_src

#+RESULTS:
: (70, 4)
: 
: 

__Note__: this was a terse expression which makes it tricky. All I did was
to make $k$ a column. By giving it a column for $k$ and a 'row' for lambda
it will evaluate the pmf over both and produce an array that has $k$ rows
and lambda columns. This is an efficient way of producing many distributions
all at once, and __you will see it used again below__!

# In[15]:

#+BEGIN_SRC python :session *Python-3.x* :exports both :results file
def plot_it(filename):
    fig, ax = plt.subplots(figsize=(6,2.5))
    ax.set(title='Poisson Distribution of Cases\n $p(k|\lambda)$')
    plt.plot(k, y,
        marker='o',
        markersize=3,
        lw=0
    )
    plt.legend(title="$\lambda$", labels=lambdas)
    fig.savefig(filename)
    return filename
    
plot_it(filename='./img/systrom-1.png')
#+end_src

#+RESULTS:
[[file:./img/systrom-1.png]]

The Poisson distribution says that if you think you're going to have $\lambda$
cases per day, you'll probably get that many, plus or minus some variation
based on chance.

But in our case, we know there have been $k$ cases and we need to know what
value of $\lambda$ is most likely. In order to do this, we fix $k$ in place
while varying $\lambda$. __This is called the likelihood function.__

For example, imagine we observe $k=20$ new cases, and we want to know how
likely each $\lambda$ is:

# In[16]:

#+BEGIN_SRC python :session *Python-3.x* :exports both :results file
k = 20
lam = np.linspace(1, 45, 90)
likelihood = pd.Series(
    data=sps.poisson.pmf(k, lam),
    index=pd.Index(lam, name='$\lambda$'),
    name='lambda'
)

def plot_it(filename):
    likelihood.plot(
        title=r'Likelihood $P\left(k_t=20|\lambda\right)$', 
        figsize=(6,2.5)
    )
    plt.legend(title="$\lambda$", labels=lambdas)
    plt.savefig(filename)
    return filename
    
plot_it(filename='./img/systrom-2.png')
#+end_src

#+RESULTS:
[[file:./img/systrom-2.png]]

This says that if we see 20 cases, the most likely value of $\lambda$ is
(not surprisingly) 20. But we're not certain: it's possible lambda was 21
or 17 and saw 20 new cases by chance alone. It also says that it's unlikely
$\lambda$ was 40 and we saw 20.

Great. We have $P\left(\lambda_t|k_t\right)$ which is parameterized
by $\lambda$ but we were looking for $P\left(k_t|R_t\right)$ which is
parameterized by $R_t$. We need to know the relationship between $\lambda$
and $R_t$


\newpage
* Reference Section [REMOVE]
#+BIBLIOGRAPHY: refs cell limit:t

\appendix 
\newpage
